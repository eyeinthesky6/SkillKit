# Testing Approach Clarification

**Question:** Do we download external repos into the workspace for testing?

**Answer:** No. We create **controlled test projects** within the workspace.

---

## ğŸ¯ The Approach

### **Option 1: Controlled Test Projects (Recommended âœ…)**

**What we do:**
- Create minimal test projects in `test-projects/`
- These are **small, focused, committed to repo**
- Simulate real project structures without the complexity
- Examples: `python-project/`, `typescript-project/`, `nodejs-project/`

**Structure:**
```
test-projects/
â”œâ”€â”€ python-project/          # Minimal Python + Poetry project
â”‚   â”œâ”€â”€ pyproject.toml
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ test_app.py
â”œâ”€â”€ typescript-project/      # Minimal TypeScript project
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â””â”€â”€ src/
â””â”€â”€ nodejs-project/         # Minimal Node.js project
    â”œâ”€â”€ package.json
    â””â”€â”€ index.js
```

**Pros:**
- âœ… Small and fast
- âœ… No external dependencies
- âœ… No recursion risk (no SkillKit installed)
- âœ… Committed to repo (version controlled)
- âœ… AI can see everything
- âœ… Easy to reset between tests

**Cons:**
- âš ï¸ Not "real" projects (but simulate real scenarios)

---

### **Option 2: External Repos (NOT Recommended âŒ)**

**What we DON'T do:**
- Download real projects from GitHub
- Clone large repos into workspace
- Test on projects that might already have SkillKit

**Why NOT:**
- âŒ Large repos (hundreds of MB)
- âŒ External dependencies (slow to install)
- âŒ Might already have SkillKit (recursion!)
- âŒ Hard to control (what if they update?)
- âŒ Can't commit to our repo (too large)
- âŒ AI can't see full context easily

---

### **Option 3: Hybrid Approach (Optional ğŸ“)**

**If we need "real-world" testing:**

Create a separate directory that's **gitignored**:

```
test-projects/
â”œâ”€â”€ python-project/          # Controlled (committed)
â”œâ”€â”€ typescript-project/      # Controlled (committed)
â””â”€â”€ real-world/             # External repos (gitignored)
    â”œâ”€â”€ .gitignore          # Ignore everything here
    â”œâ”€â”€ some-real-project/   # Cloned from GitHub
    â””â”€â”€ another-project/     # Cloned from GitHub
```

**Usage:**
```bash
# Clone external repo (one-time, manual)
cd test-projects/real-world
git clone https://github.com/some-user/some-project.git

# Test on it
cd some-project
pnpm link @trinity-os/skillkit
tsk init
# ... test ...

# Results still captured to test-results/ (in workspace)
```

**Pros:**
- âœ… Real-world scenarios
- âœ… Doesn't pollute main repo
- âœ… Results still visible to AI

**Cons:**
- âš ï¸ Manual setup
- âš ï¸ Need to manage external repos
- âš ï¸ Risk of recursion if they have SkillKit

---

## ğŸ¯ Recommended Strategy for SkillKit

### **Primary: Controlled Test Projects**

1. **Create minimal test projects** that simulate real scenarios:
   - Python + Poetry (âœ… exists: `python-project/`)
   - TypeScript + npm
   - Node.js + pnpm
   - Monorepo structure
   - Empty project (fresh install test)

2. **These are committed to repo:**
   ```bash
   test-projects/
   â”œâ”€â”€ python-project/     # Committed âœ…
   â”œâ”€â”€ typescript-project/  # Committed âœ…
   â””â”€â”€ nodejs-project/     # Committed âœ…
   ```

3. **Test workflow:**
   ```bash
   # Build SkillKit
   pnpm build
   pnpm link
   
   # Test on controlled project
   cd test-projects/python-project
   pnpm link @trinity-os/skillkit
   tsk init
   
   # Capture results
   # â†’ test-results/integration/python-project.jsonl
   ```

### **Secondary: Real-World Testing (Optional)**

If needed, use `test-projects/real-world/` (gitignored):

```bash
# .gitignore
test-projects/real-world/*
!test-projects/real-world/.gitkeep
```

**But results still go to workspace:**
```bash
# Results captured to workspace (not gitignored)
test-results/integration/real-world-some-project.jsonl
```

---

## ğŸ“‹ What We Actually Do

### **Current Setup:**
```
test-projects/
â”œâ”€â”€ python-project/          # âœ… Minimal Python project (committed)
â”‚   â”œâ”€â”€ pyproject.toml
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ test_app.py
â””â”€â”€ workflow-test/           # âœ… Test project with workflows (committed)
    â””â”€â”€ .cursor/commands/
```

### **What We Should Add:**
```
test-projects/
â”œâ”€â”€ python-project/          # âœ… Exists
â”œâ”€â”€ typescript-project/      # ğŸ“ To create
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â””â”€â”€ src/
â”œâ”€â”€ nodejs-project/         # ğŸ“ To create
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ index.js
â””â”€â”€ empty-project/          # ğŸ“ To create (fresh install test)
    â””â”€â”€ (empty, just for tsk init test)
```

### **What We DON'T Do:**
```
test-projects/
â””â”€â”€ real-repos/             # âŒ Don't clone external repos here
    â””â”€â”€ some-large-project/  # âŒ Too big, might have SkillKit
```

---

## ğŸ¯ Summary

**Answer:** No, we don't download external repos. Instead:

1. **Create minimal test projects** in `test-projects/` (committed to repo)
2. **These simulate real scenarios** without the complexity
3. **Results captured to `test-results/`** (AI-visible)
4. **Optional:** Use `test-projects/real-world/` (gitignored) for real repos if needed

**Key Principle:**
- **Controlled test projects** = Fast, reliable, AI-visible
- **External repos** = Slow, complex, risky, not recommended

**Note:** Currently `test-results/` is gitignored. For AI-agentated workflows, we should:
- Either: Commit test results (remove from .gitignore)
- Or: Store summaries in `docs/test-results/` (committed)

---

## ğŸ”§ Implementation

### **Step 1: Expand Controlled Test Projects**

```bash
# Create TypeScript test project
mkdir test-projects/typescript-project
cd test-projects/typescript-project
npm init -y
npm install typescript @types/node --save-dev
# Add minimal tsconfig.json, src/index.ts

# Create Node.js test project
mkdir test-projects/nodejs-project
cd test-projects/nodejs-project
npm init -y
# Add minimal index.js

# Create empty project (for fresh install test)
mkdir test-projects/empty-project
# (empty, just for testing tsk init on fresh project)
```

### **Step 2: Test Runner Uses These**

```typescript
// scripts/test-integration.ts
const testProjects = [
  'python-project',
  'typescript-project',
  'nodejs-project',
  'empty-project'
];

for (const project of testProjects) {
  // Test on each controlled project
  // Capture results to test-results/integration/
}
```

### **Step 3: Results Always in Workspace**

All test results go to `test-results/` (committed to repo):
- `test-results/integration/*.jsonl` (structured data)
- `test-results/reports/*.md` (human/AI readable)

**AI can read everything!**

---

## âœ… Best Practice

**For SkillKit (AI-Agentated):**
- âœ… Use controlled test projects (committed)
- âœ… Keep them minimal and focused
- âœ… Capture all results to workspace
- âŒ Don't clone external repos (unless really needed)
- âŒ Don't test on projects that might have SkillKit

**The test projects are like "fixtures" in traditional testing - small, controlled, repeatable.**

